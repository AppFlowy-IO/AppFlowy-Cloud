use crate::error::RealtimeError;
use anyhow::anyhow;
use app_error::AppError;
use arc_swap::ArcSwap;
use collab::core::collab::{default_client_id, CollabOptions, DataSource};
use collab::core::origin::CollabOrigin;
use collab::entity::EncodedCollab;
use collab::lock::RwLock;
use collab::preclude::Collab;
use collab_entity::CollabType;
use collab_rt_entity::user::RealtimeUser;
use collab_rt_entity::{
  AckCode, AwarenessSync, BroadcastSync, CollabAck, MessageByObjectId, MsgId,
};
use collab_rt_entity::{ClientCollabMessage, CollabMessage};
use collab_rt_protocol::{Message, MessageReader, RTProtocolError, SyncMessage};
use collab_stream::client::CollabRedisStream;
use collab_stream::collab_update_sink::CollabUpdateSink;

use crate::metrics::CollabRealtimeMetrics;
use appflowy_proto::Rid;
use bytes::Bytes;
use chrono::{DateTime, Utc};
use collab_document::document::DocumentBody;
use collab_stream::awareness_gossip::AwarenessUpdateSink;
use collab_stream::error::StreamError;
use collab_stream::model::{
  AwarenessStreamUpdate, CollabStreamUpdate, MessageId, UpdateFlags, UpdateStreamMessage,
};
use dashmap::DashMap;
use database::collab::{CollabStorage, GetCollabOrigin};
use database_entity::dto::CollabParams;
use futures::{pin_mut, Sink, Stream};
use futures_util::{SinkExt, StreamExt};
use indexer::scheduler::{IndexerScheduler, UnindexedCollabTask, UnindexedData};
use std::sync::atomic::{AtomicU32, Ordering};
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::time::MissedTickBehavior;
use tokio_util::sync::CancellationToken;
use tracing::{debug, error, instrument, trace, warn};
use uuid::Uuid;
use yrs::sync::AwarenessUpdate;
use yrs::updates::decoder::{Decode, DecoderV1};
use yrs::updates::encoder::{Encode, Encoder, EncoderV1};
use yrs::{DeleteSet, ReadTxn, StateVector, Update};

/// A group used to manage a single [Collab] object
pub struct CollabGroup {
  state: Arc<CollabGroupState>,
}

/// Inner state of [CollabGroup] that's private and hidden behind Arc, so that it can be moved into
/// tasks.
struct CollabGroupState {
  workspace_id: Uuid,
  object_id: Uuid,
  collab_type: CollabType,
  /// A list of subscribers to this group. Each subscriber will receive updates from the
  /// broadcast.
  subscribers: DashMap<RealtimeUser, Subscription>,
  persister: CollabPersister,
  metrics: Arc<CollabRealtimeMetrics>,
  /// Cancellation token triggered when current collab group is about to be stopped.
  /// This will also shut down all subsequent [Subscription]s.
  shutdown: CancellationToken,
  last_activity: ArcSwap<Instant>,
  seq_no: AtomicU32,
  /// The most recent state vector from a redis update.
  state_vector: RwLock<StateVector>,
}

impl Drop for CollabGroup {
  fn drop(&mut self) {
    // we're going to use state shutdown to cancel subsequent tasks
    self.state.shutdown.cancel();
  }
}

impl CollabGroup {
  #[allow(clippy::too_many_arguments)]
  pub async fn new<S>(
    uid: i64,
    workspace_id: Uuid,
    object_id: Uuid,
    collab_type: CollabType,
    metrics: Arc<CollabRealtimeMetrics>,
    storage: Arc<S>,
    collab_redis_stream: Arc<CollabRedisStream>,
    persistence_interval: Duration,
    state_vector: StateVector,
    indexer_scheduler: Arc<IndexerScheduler>,
  ) -> Result<Self, StreamError>
  where
    S: CollabStorage,
  {
    let is_new_collab = state_vector.is_empty();
    let persister = CollabPersister::new(
      uid,
      workspace_id,
      object_id,
      collab_type,
      storage,
      collab_redis_stream,
      indexer_scheduler,
      metrics.clone(),
    )
    .await?;

    let state = Arc::new(CollabGroupState {
      workspace_id,
      object_id,
      collab_type,
      subscribers: DashMap::new(),
      metrics,
      shutdown: CancellationToken::new(),
      persister,
      last_activity: ArcSwap::new(Instant::now().into()),
      seq_no: AtomicU32::new(0),
      state_vector: state_vector.into(),
    });

    /*
     NOTE: we don't want to pass `Weak<CollabGroupState>` to tasks and terminate them when they
     cannot be upgraded since we want to be sure that ie. when collab group is to be removed,
     that we're going to call for a final save of the document state.

     For that we use `CancellationToken` instead, which is racing against internal loops of child
     tasks and triggered when this `CollabGroup` is dropped.
    */

    // setup task used to receive collab updates from Redis
    {
      let state = state.clone();
      tokio::spawn(async move {
        if let Err(err) = Self::inbound_task(state).await {
          tracing::warn!("failed to receive collab update: {}", err);
        }
      });
    }

    // setup task used to receive awareness updates from Redis
    {
      let state = state.clone();
      tokio::spawn(async move {
        if let Err(err) = Self::inbound_awareness_task(state).await {
          tracing::warn!("failed to receive awareness update: {}", err);
        }
      });
    }

    // setup periodic snapshot
    {
      tokio::spawn(Self::snapshot_task(
        state.clone(),
        persistence_interval,
        is_new_collab,
      ));
    }

    Ok(Self { state })
  }

  #[inline]
  pub fn workspace_id(&self) -> &Uuid {
    &self.state.workspace_id
  }

  #[inline]
  #[allow(dead_code)]
  pub fn object_id(&self) -> &Uuid {
    &self.state.object_id
  }

  pub fn is_cancelled(&self) -> bool {
    self.state.shutdown.is_cancelled()
  }

  /// Task used to receive collab updates from Redis.
  async fn inbound_task(state: Arc<CollabGroupState>) -> Result<(), RealtimeError> {
    let updates = state.persister.collab_redis_stream.live_collab_updates(
      &state.workspace_id,
      &state.object_id,
      None,
    );
    pin_mut!(updates);
    loop {
      tokio::select! {
        _ = state.shutdown.cancelled() => {
          break;
        }
        res = updates.next() => {
          match res {
            Some(Ok((message_id, update))) => {
              state.metrics.observe_collab_stream_latency(message_id.timestamp_ms);
              state.persister.storage.mark_as_editing(state.object_id);
              Self::handle_inbound_update(&state, update).await;
            },
            Some(Err(err)) => {
              tracing::warn!("failed to handle incoming update for collab `{}`: {}", state.object_id, err);
              break;
            },
            None => {
              break;
            }
          }
        }
      }
    }
    Ok(())
  }

  #[instrument(level = "trace", skip_all)]
  async fn handle_inbound_update(state: &CollabGroupState, update: CollabStreamUpdate) {
    let sender = update.sender.clone();
    match update.into_update() {
      Ok(update) => {
        let mut update_sv = StateVector::default();
        let insertions = update.insertions(true);
        let del_set = DeleteSet::from(insertions);
        for (&client, blocks) in del_set.iter() {
          if blocks.is_empty() {
            continue;
          }
          let upper = blocks.iter().map(|b| b.end).max().unwrap();
          update_sv.set_max(client, upper);
        }

        trace!(
          "receive inbound {}/{} update {:#?}, state vector: {:#?}, server state vector: {:#?}",
          state.object_id,
          state.collab_type,
          update,
          update_sv,
          state.state_vector.read().await,
        );
        state.state_vector.write().await.merge(update_sv);

        let seq_num = state.seq_no.fetch_add(1, Ordering::SeqCst) + 1;
        let payload = Message::Sync(SyncMessage::Update(update.encode_v1())).encode_v1();
        let message = BroadcastSync::new(sender, state.object_id.to_string(), payload, seq_num);
        for mut e in state.subscribers.iter_mut() {
          let subscription = e.value_mut();
          if message.origin == subscription.collab_origin {
            continue; // don't send update to its sender
          }

          if let Err(err) = subscription.sink.send(message.clone().into()).await {
            tracing::debug!(
              "failed to send collab `{}` update to `{}`: {}",
              state.object_id,
              subscription.collab_origin,
              err
            );
          }

          state.last_activity.store(Arc::new(Instant::now()));
        }
      },
      Err(err) => {
        tracing::error!(
          "received malformed update for collab `{}`: {}",
          state.object_id,
          err
        );
      },
    }
  }

  /// Task used to receive awareness updates from Redis.
  async fn inbound_awareness_task(state: Arc<CollabGroupState>) -> Result<(), RealtimeError> {
    let object_id = state.object_id;
    let updates = state
      .persister
      .collab_redis_stream
      .awareness_updates(&object_id);
    pin_mut!(updates);
    loop {
      tokio::select! {
        _ = state.shutdown.cancelled() => {
          break;
        }
        res = updates.recv() => {
          match res {
            Some(awareness_update) => {
              Self::handle_inbound_awareness(&state, &awareness_update).await;
            },
            None => {
              break;
            }
          }
        }
      }
    }
    Ok(())
  }

  async fn handle_inbound_awareness(state: &CollabGroupState, update: &AwarenessStreamUpdate) {
    tracing::trace!("broadcast awareness {:#?}", update.data,);
    let sender = &update.sender;
    let message = AwarenessSync::new(
      state.object_id.to_string(),
      Message::Awareness(update.data.encode_v1()).encode_v1(),
      CollabOrigin::Empty,
    );
    for mut e in state.subscribers.iter_mut() {
      let subscription = e.value_mut();
      if sender == &subscription.collab_origin {
        continue; // don't send update to its sender
      }

      if let Err(err) = subscription.sink.send(message.clone().into()).await {
        tracing::debug!(
          "failed to send awareness `{}` update to `{}`: {}",
          state.object_id,
          subscription.collab_origin,
          err
        );
      }

      state.last_activity.store(Arc::new(Instant::now()));
    }
  }

  async fn snapshot_task(state: Arc<CollabGroupState>, interval: Duration, is_new_collab: bool) {
    if is_new_collab {
      tracing::trace!("persisting new collab for {}", state.object_id);
      if let Err(err) = state.persister.save().await {
        tracing::warn!(
          "failed to persist new document `{}`: {}",
          state.object_id,
          err
        );
      }
    }

    let mut snapshot_tick = tokio::time::interval(interval);
    // if saving took longer than snapshot_tick, just skip it over and try in the next round
    snapshot_tick.set_missed_tick_behavior(MissedTickBehavior::Skip);

    loop {
      tokio::select! {
        _ = snapshot_tick.tick() => {
          if let Err(err) = state.persister.save().await {
            tracing::warn!("failed to persist collab `{}/{}`: {}", state.workspace_id, state.object_id, err);
          }
        },
        _ = state.shutdown.cancelled() => {
          if let Err(err) = state.persister.save().await {
            tracing::warn!("failed to persist collab on shutdown `{}/{}`: {}", state.workspace_id, state.object_id, err);
          }
          break;
        }
      }
    }
  }

  pub async fn calculate_missing_update(
    &self,
    state_vector: StateVector,
  ) -> Result<Vec<u8>, RealtimeError> {
    {
      // first check if we need to send any updates
      let collab_sv = self.state.state_vector.read().await;
      if *collab_sv <= state_vector {
        return Ok(vec![]);
      }
    }

    let encoded_collab = self.encode_collab().await?;
    let options = CollabOptions::new(self.object_id().to_string(), default_client_id())
      .with_data_source(DataSource::DocStateV1(encoded_collab.doc_state.into()));
    let collab = Collab::new_with_options(CollabOrigin::Server, options)?;
    let update = collab.transact().encode_state_as_update_v1(&state_vector);
    Ok(update)
  }

  /// Generate embedding for the current Collab immediately
  ///
  pub async fn generate_embeddings(&self) -> Result<(), AppError> {
    let collab = self
      .encode_collab()
      .await
      .map_err(|e| AppError::Internal(e.into()))?;
    let options = CollabOptions::new(self.object_id().to_string(), default_client_id())
      .with_data_source(DataSource::DocStateV1(collab.doc_state.into()));
    let collab = Collab::new_with_options(CollabOrigin::Server, options)
      .map_err(|e| AppError::Internal(e.into()))?;
    let workspace_id = self.state.workspace_id;
    let object_id = self.state.object_id;
    let collab_type = self.state.collab_type;
    self
      .state
      .persister
      .indexer_scheduler
      .index_collab_immediately(workspace_id, object_id, &collab, collab_type)
      .await
  }

  pub async fn encode_collab(&self) -> Result<EncodedCollab, RealtimeError> {
    let snapshot = self.state.persister.load_compact().await?;
    let encode_collab = snapshot.collab.encode_collab_v1(|collab| {
      self
        .state
        .collab_type
        .validate_require_data(collab)
        .map_err(|err| RealtimeError::CollabSchemaError(err.to_string()))
    })?;
    Ok(encode_collab)
  }

  pub fn contains_user(&self, user: &RealtimeUser) -> bool {
    self.state.subscribers.contains_key(user)
  }

  pub fn remove_user(&self, user: &RealtimeUser) {
    if self.state.subscribers.remove(user).is_some() {
      trace!(
        "{} remove subscriber from group: {}",
        self.state.object_id,
        user
      );
    }
  }

  pub fn user_count(&self) -> usize {
    self.state.subscribers.len()
  }

  pub fn modified_at(&self) -> Instant {
    *self.state.last_activity.load_full()
  }

  /// Subscribes a new connection to the broadcast group for collaborative activities.
  ///
  pub fn subscribe<Sink, Stream>(
    &self,
    user: &RealtimeUser,
    subscriber_origin: CollabOrigin,
    sink: Sink,
    stream: Stream,
  ) where
    Sink: SubscriptionSink + Clone + 'static,
    Stream: SubscriptionStream + 'static,
  {
    // create new subscription for new subscriber
    let subscriber_shutdown = self.state.shutdown.child_token();

    tokio::spawn(Self::receive_from_client_task(
      self.state.clone(),
      sink.clone(),
      stream,
      subscriber_origin.clone(),
    ));

    let sub = Subscription::new(sink, subscriber_origin, subscriber_shutdown);
    if self
      .state
      .subscribers
      .insert((*user).clone(), sub)
      .is_some()
    {
      tracing::warn!("{}: remove old subscriber: {}", &self.state.object_id, user);
    }

    if cfg!(debug_assertions) {
      trace!(
        "{}: add new subscriber, current group member: {}",
        &self.state.object_id,
        self.user_count(),
      );
    }

    trace!(
      "[realtime]:{} new subscriber:{}, connect at:{}, connected members: {}",
      self.state.object_id,
      user.user_device(),
      user.connect_at,
      self.state.subscribers.len(),
    );
  }

  async fn receive_from_client_task<Sink, Stream>(
    state: Arc<CollabGroupState>,
    mut sink: Sink,
    mut stream: Stream,
    origin: CollabOrigin,
  ) where
    Sink: SubscriptionSink + 'static,
    Stream: SubscriptionStream + 'static,
  {
    loop {
      tokio::select! {
        _ = state.shutdown.cancelled() => {
          break;
        }
        msg = stream.next() => {
          match msg {
            None => break,
            Some(msg) => if let Err(err) =  Self::handle_messages(&state, &mut sink, msg).await {
              tracing::warn!(
                "collab `{}` failed to handle message from `{}`: {}",
                state.object_id,
                origin,
                err
              );

            }
          }
        }
      }
    }
  }

  async fn handle_messages<Sink>(
    state: &CollabGroupState,
    sink: &mut Sink,
    msg: MessageByObjectId,
  ) -> Result<(), RealtimeError>
  where
    Sink: SubscriptionSink + 'static,
  {
    let object_id = state.object_id.to_string();
    for (message_object_id, messages) in msg.0 {
      if object_id != message_object_id {
        error!(
          "Expect object id:{} but got:{}",
          state.object_id, message_object_id
        );
        continue;
      }
      for message in messages {
        match Self::handle_client_message(state, message).await {
          Ok(response) => match sink.send(response.into()).await {
            Ok(()) => {},
            Err(err) => {
              trace!("[realtime]: send failed: {}", err);
              break;
            },
          },
          Err(err) => {
            error!(
              "Error handling collab message for object_id: {}: {}",
              message_object_id, err
            );
            break;
          },
        }
      }
    }
    Ok(())
  }

  /// Handle the message sent from the client
  async fn handle_client_message(
    state: &CollabGroupState,
    collab_msg: ClientCollabMessage,
  ) -> Result<CollabAck, RealtimeError> {
    let msg_id = collab_msg.msg_id();
    let message_origin = collab_msg.origin().clone();

    // If the payload is empty, we don't need to apply any updates .
    // Currently, only the ping message should has an empty payload.
    if collab_msg.payload().is_empty() {
      if !matches!(collab_msg, ClientCollabMessage::ClientCollabStateCheck(_)) {
        error!("receive unexpected empty payload message:{}", collab_msg);
      }
      return Ok(CollabAck::new(
        message_origin,
        state.object_id.to_string(),
        msg_id,
        state.seq_no.load(Ordering::SeqCst),
      ));
    }

    let payload = collab_msg.payload();

    // Spawn a blocking task to handle the message
    let result = Self::handle_message(state, payload, &message_origin, msg_id).await;

    match result {
      Ok(inner_result) => match inner_result {
        Some(response) => Ok(response),
        None => Err(RealtimeError::UnexpectedData("No ack response")),
      },
      Err(err) => Err(RealtimeError::Internal(anyhow!(
        "fail to handle message:{}",
        err
      ))),
    }
  }

  async fn handle_message(
    state: &CollabGroupState,
    payload: &[u8],
    message_origin: &CollabOrigin,
    msg_id: MsgId,
  ) -> Result<Option<CollabAck>, RealtimeError> {
    let mut decoder = DecoderV1::from(payload);
    let reader = MessageReader::new(&mut decoder);
    let mut ack_response = None;
    for msg in reader {
      match msg {
        Ok(msg) => {
          match Self::handle_protocol_message(state, message_origin, msg).await {
            Ok(payload) => {
              // One ClientCollabMessage can have multiple Yrs [Message] in it, but we only need to
              // send one ack back to the client.
              if ack_response.is_none() {
                ack_response = Some(
                  CollabAck::new(
                    CollabOrigin::Server,
                    state.object_id.to_string(),
                    msg_id,
                    state.seq_no.load(Ordering::SeqCst),
                  )
                  .with_payload(payload.unwrap_or_default()),
                );
              }
            },
            Err(err) => {
              tracing::warn!("[realtime]: failed to handled message: {}", err);
              state.metrics.apply_update_failed_count.inc();

              let code = Self::ack_code_from_error(&err);
              let payload = match err {
                RTProtocolError::MissUpdates {
                  state_vector_v1,
                  reason: _,
                } => state_vector_v1.unwrap_or_default(),
                _ => vec![],
              };

              ack_response = Some(
                CollabAck::new(
                  CollabOrigin::Server,
                  state.object_id.to_string(),
                  msg_id,
                  state.seq_no.load(Ordering::SeqCst),
                )
                .with_code(code)
                .with_payload(payload),
              );

              break;
            },
          }
        },
        Err(e) => {
          error!("{} => parse sync message failed: {}", state.object_id, e);
          break;
        },
      }
    }
    Ok(ack_response)
  }

  async fn handle_protocol_message(
    state: &CollabGroupState,
    origin: &CollabOrigin,
    msg: Message,
  ) -> Result<Option<Vec<u8>>, RTProtocolError> {
    match msg {
      Message::Sync(msg) => match msg {
        SyncMessage::SyncStep1(sv) => Self::handle_sync_step1(state, &sv).await,
        SyncMessage::SyncStep2(update) => Self::handle_sync_step2(state, origin, update).await,
        SyncMessage::Update(update) => Self::handle_update(state, origin, update).await,
      },
      //FIXME: where is the QueryAwareness protocol?
      Message::Awareness(update) => Self::handle_awareness_update(state, origin, update).await,
      Message::Auth(_reason) => Ok(None),
      Message::Custom(_msg) => Ok(None),
    }
  }

  async fn handle_sync_step1(
    state: &CollabGroupState,
    client_sv: &StateVector,
  ) -> Result<Option<Vec<u8>>, RTProtocolError> {
    if let Ok(sv) = state.state_vector.try_read() {
      trace!(
        "Sync step1: {}/{} server state vector: {:#?}, client state vector: {:#?}",
        state.object_id,
        state.collab_type,
        sv,
        client_sv
      );
      // we optimistically try to obtain state vector lock for a fast track:
      // if we remote sv is up-to-date with current one, we don't need to do anything
      match sv.partial_cmp(client_sv) {
        Some(std::cmp::Ordering::Equal) => {
          trace!(
            "Sync step1: {}/{} client and server are synced, no need to send anything",
            state.object_id,
            state.collab_type
          );
          return Ok(None);
        }, // client and server are in sync
        Some(std::cmp::Ordering::Less) => {
          // server is behind client
          trace!(
            "Sync step1: server {}/{} is behind client, sending sync step 1 with state vector: {:#?}",
            state.object_id, state.collab_type,
            sv
          );
          let msg = Message::Sync(SyncMessage::SyncStep1(sv.clone()));
          return Ok(Some(msg.encode_v1()));
        },
        Some(std::cmp::Ordering::Greater) | None => {
          // server has some new updates
          trace!(
            "Sync step1: server has some new updates for {}/{}",
            state.object_id,
            state.collab_type
          );
        },
      }
    }

    // we need to reconstruct document state on the server side
    tracing::debug!("loading collab {}", state.object_id);
    let snapshot = state
      .persister
      .load_compact()
      .await
      .map_err(|err| RTProtocolError::Internal(err.into()))?;

    // prepare document state update and state vector
    let tx = snapshot.collab.transact();
    let doc_state = tx.encode_diff_v1(client_sv);
    let local_sv = tx.state_vector();
    drop(tx);

    // Retrieve the latest document state from the client after they return online from offline editing.
    tracing::trace!("sending missing data to client ({} bytes)", doc_state.len());
    let mut encoder = EncoderV1::new();
    Message::Sync(SyncMessage::SyncStep2(doc_state)).encode(&mut encoder);
    //FIXME: this should never happen as response to sync step 1 from the client, but rather be
    //  send when a connection is established
    Message::Sync(SyncMessage::SyncStep1(local_sv)).encode(&mut encoder);
    Ok(Some(encoder.to_vec()))
  }

  async fn handle_sync_step2(
    state: &CollabGroupState,
    origin: &CollabOrigin,
    update: Vec<u8>,
  ) -> Result<Option<Vec<u8>>, RTProtocolError> {
    state.metrics.collab_size.observe(update.len() as f64);

    let start = tokio::time::Instant::now();
    // we try to decode update to make sure it's not malformed and to extract state vector
    let (update, decoded_update) = if update.len() <= collab_rt_protocol::LARGE_UPDATE_THRESHOLD {
      let decoded_update = Update::decode_v1(&update)?;
      (update, decoded_update)
    } else {
      tokio::task::spawn_blocking(move || {
        let decoded_update = Update::decode_v1(&update)?;
        Ok::<(Vec<u8>, yrs::Update), yrs::encoding::read::Error>((update, decoded_update))
      })
      .await
      .map_err(|err| RTProtocolError::Internal(err.into()))??
    };

    state
      .metrics
      .load_collab_time
      .observe(start.elapsed().as_millis() as f64);

    let (should_apply_update, missing_updates) = {
      let current_sv = state.state_vector.read().await;
      let update_sv = decoded_update.state_vector_lower();
      trace!(
        "Sync step2: {}/{} new update: {:#?}, state vector: {:#?}, server state vector: {:#?}",
        state.object_id,
        state.collab_type,
        decoded_update,
        update_sv,
        current_sv,
      );
      match current_sv.partial_cmp(&update_sv) {
        None => {
          // Concurrent state vectors: both server and client have updates the other hasn't seen
          // We should apply the update to merge the states, then inform the client of our state
          trace!(
            "Sync step2: {}/{} concurrent state vectors, current: {:#?}, update: {:#?}",
            state.object_id,
            state.collab_type,
            current_sv,
            update_sv
          );
          (
            true,
            Some(Message::Sync(SyncMessage::SyncStep1(current_sv.clone())).encode_v1()),
          )
        },
        Some(std::cmp::Ordering::Less) => {
          if !decoded_update.extends(&current_sv) {
            // server is behind client, but the update doesn't extend current server state
            // which means that we must have missed some updates, that must be integrated
            // before current update can be fully applied
            trace!(
              "Sync step2: server {}/{} is behind client",
              state.object_id,
              state.collab_type,
            );
            return Ok(Some(
              Message::Sync(SyncMessage::SyncStep1(current_sv.clone())).encode_v1(),
            ));
          } else {
            (true, None)
          }
        },
        Some(std::cmp::Ordering::Equal) => {
          trace!(
            "Sync step2: {}/{} server and client are synced",
            state.object_id,
            state.collab_type,
          );
          (true, None)
        },
        Some(std::cmp::Ordering::Greater) => {
          trace!(
            "Sync step2: {}/{} server is ahead of client",
            state.object_id,
            state.collab_type,
          );
          (true, None)
        },
      }
    };

    if should_apply_update {
      state
        .persister
        .send_update(origin.clone(), update)
        .await
        .map_err(|err| RTProtocolError::Internal(err.into()))?;
    }

    Ok(missing_updates)
  }

  async fn handle_update(
    state: &CollabGroupState,
    origin: &CollabOrigin,
    update: Vec<u8>,
  ) -> Result<Option<Vec<u8>>, RTProtocolError> {
    Self::handle_sync_step2(state, origin, update).await
  }

  async fn handle_awareness_update(
    state: &CollabGroupState,
    origin: &CollabOrigin,
    update: Vec<u8>,
  ) -> Result<Option<Vec<u8>>, RTProtocolError> {
    let awareness_update = AwarenessUpdate::decode_v1(&update)?;
    trace!("awareness updates: {:#?}", awareness_update);
    state
      .persister
      .send_awareness(origin, awareness_update)
      .await
      .map_err(|err| RTProtocolError::Internal(err.into()))?;
    Ok(None)
  }

  #[inline]
  fn ack_code_from_error(error: &RTProtocolError) -> AckCode {
    match error {
      RTProtocolError::YrsTransaction(_) => AckCode::Retry,
      RTProtocolError::YrsApplyUpdate(_) => AckCode::CannotApplyUpdate,
      RTProtocolError::YrsEncodeState(_) => AckCode::EncodeStateAsUpdateFail,
      RTProtocolError::MissUpdates { .. } => AckCode::MissUpdate,
      _ => AckCode::Internal,
    }
  }

  /// Check if the group is active. A group is considered active if it has at least one
  /// subscriber
  pub fn is_inactive(&self) -> bool {
    let modified_at = self.modified_at();
    let elapsed_secs = modified_at.elapsed().as_secs();
    // Mark the group as inactive if it has been inactive for more than 3 hours, regardless of the number of subscribers.
    // Otherwise, return `true` only if there are no subscribers remaining in the group.
    // If a client modifies a group that has already been marked as inactive (removed),
    // the client will automatically send an initialization sync to reinitialize the group.
    const MAXIMUM_SECS: u64 = 3 * 60 * 60;
    if elapsed_secs > MAXIMUM_SECS {
      debug!(
        "Group:{}:{} is inactive for {} seconds, subscribers: {}",
        self.state.object_id,
        self.state.collab_type,
        modified_at.elapsed().as_secs(),
        self.state.subscribers.len()
      );
      true
    } else {
      self.state.subscribers.is_empty()
    }
  }
}

pub trait SubscriptionSink:
  Sink<CollabMessage, Error = RealtimeError> + Send + Sync + Unpin
{
}
impl<T> SubscriptionSink for T where
  T: Sink<CollabMessage, Error = RealtimeError> + Send + Sync + Unpin
{
}

pub trait SubscriptionStream: Stream<Item = MessageByObjectId> + Send + Sync + Unpin {}
impl<T> SubscriptionStream for T where T: Stream<Item = MessageByObjectId> + Send + Sync + Unpin {}

struct Subscription {
  collab_origin: CollabOrigin,
  sink: Box<dyn SubscriptionSink>,
  shutdown: CancellationToken,
}

impl Subscription {
  fn new<S>(sink: S, collab_origin: CollabOrigin, shutdown: CancellationToken) -> Self
  where
    S: SubscriptionSink + 'static,
  {
    Subscription {
      sink: Box::new(sink),
      collab_origin,
      shutdown,
    }
  }
}

impl Drop for Subscription {
  fn drop(&mut self) {
    tracing::trace!("closing subscription: {}", self.collab_origin);
    self.shutdown.cancel();
  }
}

struct CollabPersister {
  uid: i64,
  workspace_id: Uuid,
  object_id: Uuid,
  collab_type: CollabType,
  storage: Arc<dyn CollabStorage>,
  collab_redis_stream: Arc<CollabRedisStream>,
  indexer_scheduler: Arc<IndexerScheduler>,
  metrics: Arc<CollabRealtimeMetrics>,
  update_sink: CollabUpdateSink,
  awareness_sink: AwarenessUpdateSink,
}

impl CollabPersister {
  #[allow(clippy::too_many_arguments)]
  pub async fn new(
    uid: i64,
    workspace_id: Uuid,
    object_id: Uuid,
    collab_type: CollabType,
    storage: Arc<dyn CollabStorage>,
    collab_redis_stream: Arc<CollabRedisStream>,
    indexer_scheduler: Arc<IndexerScheduler>,
    metrics: Arc<CollabRealtimeMetrics>,
  ) -> Result<Self, StreamError> {
    let update_sink =
      collab_redis_stream.collab_update_sink(&workspace_id, &object_id, collab_type);
    let awareness_sink = collab_redis_stream
      .awareness_update_sink(&workspace_id, &object_id)
      .await?;
    Ok(Self {
      uid,
      workspace_id,
      object_id,
      collab_type,
      storage,
      collab_redis_stream,
      indexer_scheduler,
      metrics,
      update_sink,
      awareness_sink,
    })
  }

  #[instrument(level = "trace", skip_all)]
  async fn send_update(
    &self,
    sender: CollabOrigin,
    update: Vec<u8>,
  ) -> Result<MessageId, StreamError> {
    let len = update.len();
    // send updates to redis queue
    let update = CollabStreamUpdate::new(update, sender, UpdateFlags::default());
    let msg_id = self.update_sink.send(&update).await?;
    self.storage.mark_as_editing(self.object_id);
    tracing::trace!(
      "persisted update for {} from {} ({} bytes) - msg id: {}",
      self.object_id,
      update.sender,
      len,
      msg_id
    );
    Ok(msg_id)
  }

  async fn send_awareness(
    &self,
    sender_session: &CollabOrigin,
    awareness_update: AwarenessUpdate,
  ) -> Result<(), StreamError> {
    let update = AwarenessStreamUpdate {
      data: awareness_update,
      sender: sender_session.clone(),
    };
    self.awareness_sink.send(&update).await?;
    trace!("broadcast awareness {:#?}", update);
    Ok(())
  }

  /// Loads collab without its history. Used for handling y-sync protocol messages.
  async fn load_compact(&self) -> Result<CollabSnapshot, RealtimeError> {
    tracing::trace!("requested to load compact collab {}", self.object_id);
    // 1. Try to load the latest snapshot from storage
    let start = Instant::now();
    let (rid, mut collab) = match self.load_collab_full().await? {
      Some((rid, collab)) => (rid, collab),
      None => {
        let options = CollabOptions::new(self.object_id.to_string(), default_client_id());
        let collab = Collab::new_with_options(CollabOrigin::Server, options)?;
        (Rid::default(), collab)
      },
    };
    self.metrics.load_collab_count.inc();
    let since = MessageId::new(rid.timestamp, rid.seq_no);

    // 2. consume all Redis updates on top of it (keep redis msg id)
    let mut applied_messages = Vec::new();
    let mut tx = collab.transact_mut();
    let updates = self
      .collab_redis_stream
      .current_collab_updates(&self.workspace_id, &self.object_id, Some(since))
      .await?;
    let mut i = 0;
    for (message_id, update) in updates {
      i += 1;
      let update: Update = update.into_update()?;
      tx.apply_update(update).map_err(|err| {
        RTProtocolError::YrsApplyUpdate(format!("collab {} - {}", self.object_id, err))
      })?;
      applied_messages.push(message_id); //TODO: shouldn't this happen before decoding?
      self.metrics.apply_update_count.inc();
    }

    drop(tx);
    tracing::trace!(
      "loaded collab compact state: {} replaying {} updates",
      self.object_id,
      i
    );
    self
      .metrics
      .load_collab_time
      .observe(start.elapsed().as_millis() as f64);

    // now we have the most recent version of the document
    let snapshot = CollabSnapshot {
      collab,
      rid,
      applied_messages,
    };
    Ok(snapshot)
  }

  /// Returns a collab state (with GC turned off), but only if there were any pending updates
  /// waiting to be merged into main document state.
  async fn load_if_changed(&self) -> Result<Option<CollabSnapshot>, RealtimeError> {
    // 1. load pending Redis updates
    let updates = self
      .collab_redis_stream
      .current_collab_updates(&self.workspace_id, &self.object_id, None)
      .await?;

    if updates.is_empty() {
      // if there were no Redis updates, collab is still not initialized
      return Ok(None);
    }

    let (rid, mut collab) = match self.load_collab_full().await? {
      Some(collab) => collab,
      None => {
        let options = CollabOptions::new(self.object_id.to_string(), default_client_id());
        let collab = Collab::new_with_options(CollabOrigin::Server, options)?;
        (Rid::default(), collab)
      },
    };
    let start = Instant::now();
    let mut i = 0;
    let mut applied_messages = Vec::new();
    let mut tx = collab.transact_mut();
    for (message_id, update) in updates {
      i += 1;
      let update: Update = update.into_update()?;
      tx.apply_update(update).map_err(|err| {
        RTProtocolError::YrsApplyUpdate(format!("collab {} - {}", self.object_id, err))
      })?;
      applied_messages.push(message_id); //TODO: shouldn't this happen before decoding?
      self.metrics.apply_update_count.inc();
    }
    drop(tx);

    self.metrics.load_full_collab_count.inc();
    let elapsed = start.elapsed();
    self
      .metrics
      .load_collab_time
      .observe(elapsed.as_millis() as f64);
    tracing::trace!(
      "loaded collab full state: {} replaying {} updates in {:?}",
      self.object_id,
      i,
      elapsed
    );
    {
      let tx = collab.transact();
      if tx.store().pending_update().is_some() || tx.store().pending_ds().is_some() {
        tracing::trace!(
          "loaded collab {} is incomplete: has pending data",
          self.object_id
        );
      }
    }
    Ok(Some(CollabSnapshot {
      collab,
      rid,
      applied_messages,
    }))
  }

  async fn save(&self) -> Result<(), RealtimeError> {
    // load collab but only if there were pending updates in Redis
    if let Some(snapshot) = self.load_if_changed().await? {
      tracing::debug!("requesting save for collab {}", self.object_id);
      if !snapshot.applied_messages.is_empty() {
        // non-nil message_id means that we had to update the most recent collab state snapshot
        // with new updates from Redis. This means that our snapshot state is newer than the last
        // persisted one in the database
        self.save_attempt(snapshot).await?;
      }
    }
    Ok(())
  }

  /// Tries to save provided `snapshot`. This snapshot is expected to have **GC turned off**, as
  /// first it will try to save it as a historical snapshot (will all updates available), then it
  /// will generate another (compact) snapshot variant that will be used as main one for loading
  /// for the sake of y-sync protocol.
  async fn save_attempt(&self, snapshot: CollabSnapshot) -> Result<(), RealtimeError> {
    // try to acquire snapshot lease - it's possible that multiple web services will try to
    // perform snapshot at the same time, so we'll use lease to let only one of them atm.
    let last_message_id = snapshot.applied_messages.last().cloned().ok_or_else(|| {
      RealtimeError::CreateSnapshotFailed(
        "only save snapshot after some updates were applied".into(),
      )
    })?;
    if let Some(mut lease) = self
      .collab_redis_stream
      .lease(&self.workspace_id.to_string(), &self.object_id.to_string())
      .await?
    {
      let collab = snapshot.collab;
      // encode_diff doesn't include pending updates
      let tx = collab.transact();
      let doc_state_light = tx.encode_diff_v1(&StateVector::default());
      let state_vector = tx.state_vector();
      let light_len = doc_state_light.len();
      self
        .write_collab(doc_state_light, state_vector, snapshot.rid.timestamp)
        .await?;

      match self.collab_type {
        CollabType::Document => {
          let txn = collab.transact();
          if let Some(text) = DocumentBody::from_collab(&collab).map(|body| body.to_plain_text(txn))
          {
            self.index_collab_content(text);
          }
        },
        _ => {
          // TODO(nathan): support other collab type
        },
      }

      tracing::debug!(
        "persisted collab {} snapshot at {}: {} bytes",
        self.object_id,
        last_message_id,
        light_len
      );

      // 3. finally we can drop Redis messages
      let stream_key = UpdateStreamMessage::stream_key(&self.workspace_id);
      self
        .collab_redis_stream
        .delete_stream_messages(&stream_key, &snapshot.applied_messages)
        .await?;

      let _ = lease.release().await;
    }

    Ok(())
  }

  async fn write_collab(
    &self,
    doc_state_v1: Vec<u8>,
    state_vector: StateVector,
    mills_secs: u64,
  ) -> Result<(), RealtimeError> {
    let updated_at = DateTime::<Utc>::from_timestamp_millis(mills_secs as i64);
    let encoded_collab = EncodedCollab::new_v1(state_vector.encode_v1(), doc_state_v1)
      .encode_to_bytes()
      .map(Bytes::from)
      .map_err(|err| RealtimeError::BincodeEncode(err.to_string()))?;
    self
      .metrics
      .collab_size
      .observe(encoded_collab.len() as f64);
    let params = CollabParams {
      object_id: self.object_id,
      encoded_collab_v1: encoded_collab,
      collab_type: self.collab_type,
      updated_at,
    };
    self
      .storage
      .upsert_collab(self.workspace_id, &self.uid, params)
      .await
      .map_err(|err| RealtimeError::Internal(err.into()))?;
    Ok(())
  }

  fn index_collab_content(&self, paragraphs: Vec<String>) {
    let indexed_collab = UnindexedCollabTask::new(
      self.workspace_id,
      self.object_id,
      self.collab_type,
      UnindexedData::Paragraphs(paragraphs),
    );
    if let Err(err) = self
      .indexer_scheduler
      .index_pending_collab_one(indexed_collab, false)
    {
      warn!(
        "failed to index collab `{}/{}`: {}",
        self.workspace_id, self.object_id, err
      );
    }
  }

  #[instrument(level = "trace", skip_all)]
  async fn load_collab_full(&self) -> Result<Option<(Rid, Collab)>, RealtimeError> {
    // we didn't find a snapshot, or we want a lightweight collab version
    let result = self
      .storage
      .get_full_encode_collab(
        GetCollabOrigin::Server,
        &self.workspace_id,
        &self.object_id,
        self.collab_type,
      )
      .await;
    let (rid, doc_state) = match result {
      Ok(value) => (value.rid, value.encoded_collab.doc_state),
      Err(AppError::RecordNotFound(_)) => return Ok(None),
      Err(err) => return Err(RealtimeError::Internal(err.into())),
    };

    let collab: Collab = {
      let options = CollabOptions::new(self.object_id.to_string(), default_client_id())
        .with_data_source(DataSource::DocStateV1(doc_state.into()));
      Collab::new_with_options(CollabOrigin::Server, options)?
    };
    Ok(Some((rid, collab)))
  }
}

pub struct CollabSnapshot {
  pub collab: Collab,
  pub rid: Rid,
  pub applied_messages: Vec<MessageId>,
}
